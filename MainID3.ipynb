{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputasi KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6    148.0           72.0           35.0      NaN  33.6   \n",
      "1            1     85.0           66.0           29.0      NaN  26.6   \n",
      "2            8    183.0           64.0            NaN      NaN  23.3   \n",
      "3            1     89.0           66.0           23.0     94.0  28.1   \n",
      "4            0    137.0           40.0           35.0    168.0  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd #untuk memanipulasi data csv\n",
    "import numpy as np #untuk perhitungan matematika\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report #untuk menampilkan performa dari sistem yang dibuat\n",
    "\n",
    "dataAwal = pd.read_csv(\"dm2.csv\", delimiter=\";\")\n",
    "print(dataAwal.head())\n",
    "\n",
    "def imputasiKNN(dataAwal):\n",
    "    dataPos = dataAwal[dataAwal['Outcome'] == 1]\n",
    "    dataNeg = dataAwal[dataAwal['Outcome'] == 0]\n",
    "\n",
    "    dataPosIndex = dataPos.index\n",
    "    dataNegIndex = dataNeg.index\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=10)\n",
    "\n",
    "    datajadiPos = pd.DataFrame(imputer.fit_transform(dataPos), index=dataPosIndex, columns=dataAwal.columns)\n",
    "    datajadiNeg = pd.DataFrame(imputer.fit_transform(dataNeg), index=dataNegIndex, columns=dataAwal.columns)\n",
    "\n",
    "    dataImputer = pd.concat([datajadiPos, datajadiNeg])\n",
    "    dataImputer = dataImputer.sort_index()\n",
    "\n",
    "    #dataImputer.to_csv(\"DataImputer2.csv\", index=False)\n",
    "    #print(dataImputer)\n",
    "    \n",
    "    return dataImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diskritisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pregRendah(x) :\n",
    "    rdh = [1,2]\n",
    "    if x<=rdh[0] :\n",
    "        return 1\n",
    "    elif rdh[0]<=x and x<=rdh[1] :\n",
    "        return (rdh[1]-x)/(rdh[1]-rdh[0])\n",
    "    elif x >= rdh[1] :\n",
    "        return 0\n",
    "\n",
    "def pregNormal(x) : \n",
    "    nml = [1,2,4,5]\n",
    "    if x<=nml[0] :\n",
    "        return 0\n",
    "    elif nml[0]<=x and x<=nml[1] :\n",
    "        return (x-nml[0])/(nml[1]-nml[0])\n",
    "    elif nml[1]<=x and x<=nml[2] :\n",
    "        return 1\n",
    "    elif nml[2]<=x and x<=nml[3] :\n",
    "        return (nml[3]-x)/(nml[3]-nml[2])\n",
    "    elif x >= nml[3] :\n",
    "        return 0\n",
    "    \n",
    "def pregTinggi(x) :\n",
    "    tgi = [4,5]\n",
    "    if x<=tgi[0] :\n",
    "        return 0\n",
    "    elif tgi[0]<=x and x<=tgi[1] :\n",
    "        return (x-tgi[0])/(tgi[1]-tgi[0])\n",
    "    elif x >= tgi[1] :\n",
    "        return 1\n",
    "\n",
    "def FuzzyPregnancies(data) :\n",
    "    Preg = data['Pregnancies']\n",
    "    pRendah = []\n",
    "    pNormal = []\n",
    "    pTinggi = []\n",
    "\n",
    "    for i in Preg:\n",
    "        pRendah.append((pregRendah(i)))\n",
    "        pNormal.append((pregNormal(i)))\n",
    "        pTinggi.append((pregTinggi(i)))\n",
    "        \n",
    "    #print(pRendah[0:5])\n",
    "    #print(pNormal[0:5])\n",
    "    #print(pTinggi[0:5])\n",
    "    \n",
    "    fPreg = []\n",
    "    for h in range(len(Preg)):\n",
    "        if pRendah[h] > pNormal[h]:\n",
    "            fPreg.append(\"Rendah\")\n",
    "        elif pNormal[h] > pTinggi[h]:\n",
    "            fPreg.append(\"Normal\")\n",
    "        else:\n",
    "            fPreg.append(\"Tinggi\")\n",
    "    \n",
    "    #print(fPreg[0:5])\n",
    "    return fPreg\n",
    "\n",
    "def gluRendah(x) : \n",
    "    rdh = [135,145]\n",
    "    if x<=rdh[0] :\n",
    "        return 1\n",
    "    elif rdh[0]<=x and x<=rdh[1] :\n",
    "        return (rdh[1]-x)/(rdh[1]-rdh[0])\n",
    "    elif x >= rdh[1] :\n",
    "        return 0\n",
    "\n",
    "def gluNormal(x) : \n",
    "    nml = [135,145,195,205]\n",
    "    if x<=nml[0] :\n",
    "        return 0\n",
    "    elif nml[0]<=x and x<=nml[1] :\n",
    "        return (x-nml[0])/(nml[1]-nml[0])\n",
    "    elif nml[1]<=x and x<=nml[2] :\n",
    "        return 1\n",
    "    elif nml[2]<=x and x<=nml[3] :\n",
    "        return (nml[3]-x)/(nml[3]-nml[2])\n",
    "    elif x >= nml[3] :\n",
    "        return 0\n",
    "    \n",
    "def gluTinggi(x) : \n",
    "    tgi = [195,205]\n",
    "    if x<=tgi[0] :\n",
    "        return 0\n",
    "    elif tgi[0]<=x and x<=tgi[1] :\n",
    "        return (x-tgi[0])/(tgi[1]-tgi[0])\n",
    "    elif x >= tgi[1] :\n",
    "        return 1\n",
    "\n",
    "def FuzzyGlucose(data) :\n",
    "    Gluc = data['Glucose']\n",
    "    gRendah = []\n",
    "    gNormal = []\n",
    "    gTinggi = []\n",
    "\n",
    "    for i in Gluc:\n",
    "        gRendah.append((gluRendah(i)))\n",
    "        gNormal.append((gluNormal(i)))\n",
    "        gTinggi.append((gluTinggi(i)))\n",
    "        \n",
    "    #print(gRendah[0:5])\n",
    "    #print(gNormal[0:5])\n",
    "    #print(gTinggi[0:5])\n",
    "    \n",
    "    fGluc = []\n",
    "    for h in range(len(Gluc)):\n",
    "        if gRendah[h] > gNormal[h]:\n",
    "            fGluc.append(\"Rendah\")\n",
    "        elif gNormal[h] > gTinggi[h]:\n",
    "            fGluc.append(\"Normal\")\n",
    "        else:\n",
    "            fGluc.append(\"Tinggi\")\n",
    "    \n",
    "    #print(fGluc[0:5])\n",
    "    return fGluc\n",
    "\n",
    "def bPressRendah(x) : \n",
    "    rdh = [55,65]\n",
    "    if x<=rdh[0] :\n",
    "        return 1\n",
    "    elif rdh[0]<=x and x<=rdh[1] :\n",
    "        return (rdh[1]-x)/(rdh[1]-rdh[0])\n",
    "    elif x >= rdh[1] :\n",
    "        return 0\n",
    "\n",
    "def bPressNormal(x) : \n",
    "    nml = [55,65,75,85]\n",
    "    if x<=nml[0] :\n",
    "        return 0\n",
    "    elif nml[0]<=x and x<=nml[1] :\n",
    "        return (x-nml[0])/(nml[1]-nml[0])\n",
    "    elif nml[1]<=x and x<=nml[2] :\n",
    "        return 1\n",
    "    elif nml[2]<=x and x<=nml[3] :\n",
    "        return (nml[3]-x)/(nml[3]-nml[2])\n",
    "    elif x >= nml[3] :\n",
    "        return 0\n",
    "    \n",
    "def bPressTinggi(x) : \n",
    "    tgi = [75,85]\n",
    "    if x<=tgi[0] :\n",
    "        return 0\n",
    "    elif tgi[0]<=x and x<=tgi[1] :\n",
    "        return (x-tgi[0])/(tgi[1]-tgi[0])\n",
    "    elif x >= tgi[1] :\n",
    "        return 1\n",
    "\n",
    "def FuzzyBloodPressure(data) :\n",
    "    bPress = data['BloodPressure']\n",
    "    bpRendah = []\n",
    "    bpNormal = []\n",
    "    bpTinggi = []\n",
    "\n",
    "    for i in bPress:\n",
    "        bpRendah.append((bPressRendah(i)))\n",
    "        bpNormal.append((bPressNormal(i)))\n",
    "        bpTinggi.append((bPressTinggi(i)))\n",
    "        \n",
    "    #print(bpRendah[0:5])\n",
    "    #print(bpNormal[0:5])\n",
    "    #print(bpTinggi[0:5])\n",
    "    \n",
    "    fBP = []\n",
    "    for h in range(len(bPress)):\n",
    "        if bpRendah[h] > bpNormal[h]:\n",
    "            fBP.append(\"Rendah\")\n",
    "        elif bpNormal[h] > bpTinggi[h]:\n",
    "            fBP.append(\"Normal\")\n",
    "        else:\n",
    "            fBP.append(\"Tinggi\")\n",
    "    \n",
    "    #print(fBP[0:5])\n",
    "    return fBP\n",
    "\n",
    "def sThickRendah(x) : \n",
    "    rdh = [15.5,17.5]\n",
    "    if x<=rdh[0] :\n",
    "        return 1\n",
    "    elif rdh[0]<=x and x<=rdh[1] :\n",
    "        return (rdh[1]-x)/(rdh[1]-rdh[0])\n",
    "    elif x >= rdh[1] :\n",
    "        return 0\n",
    "\n",
    "def sThickNormal(x) : \n",
    "    nml = [15.5,17.5,28,30]\n",
    "    if x<=nml[0] :\n",
    "        return 0\n",
    "    elif nml[0]<=x and x<=nml[1] :\n",
    "        return (x-nml[0])/(nml[1]-nml[0])\n",
    "    elif nml[1]<=x and x<=nml[2] :\n",
    "        return 1\n",
    "    elif nml[2]<=x and x<=nml[3] :\n",
    "        return (nml[3]-x)/(nml[3]-nml[2])\n",
    "    elif x >= nml[3] :\n",
    "        return 0\n",
    "    \n",
    "def sThickTinggi(x) : \n",
    "    tgi = [28,30]\n",
    "    if x<=tgi[0] :\n",
    "        return 0\n",
    "    elif tgi[0]<=x and x<=tgi[1] :\n",
    "        return (x-tgi[0])/(tgi[1]-tgi[0])\n",
    "    elif x >= tgi[1] :\n",
    "        return 1\n",
    "\n",
    "def FuzzySkinThickness(data) :\n",
    "    sThick = data['SkinThickness']\n",
    "    stRendah = []\n",
    "    stNormal = []\n",
    "    stTinggi = []\n",
    "\n",
    "    for i in sThick:\n",
    "        stRendah.append((sThickRendah(i)))\n",
    "        stNormal.append((sThickNormal(i)))\n",
    "        stTinggi.append((sThickTinggi(i)))\n",
    "        \n",
    "    #print(stRendah[0:5])\n",
    "    #print(stNormal[0:5])\n",
    "    #print(stTinggi[0:5])\n",
    "    \n",
    "    fST = []\n",
    "    for h in range(len(sThick)):\n",
    "        if stRendah[h] > stNormal[h]:\n",
    "            fST.append(\"Rendah\")\n",
    "        elif stNormal[h] > stTinggi[h]:\n",
    "            fST.append(\"Normal\")\n",
    "        else:\n",
    "            fST.append(\"Tinggi\")\n",
    "    \n",
    "    #print(fST[0:5])\n",
    "    return fST\n",
    "\n",
    "def insRendah(x) : \n",
    "    rdh = [115,125]\n",
    "    if x<=rdh[0] :\n",
    "        return 1\n",
    "    elif rdh[0]<=x and x<=rdh[1] :\n",
    "        return (rdh[1]-x)/(rdh[1]-rdh[0])\n",
    "    elif x >= rdh[1] :\n",
    "        return 0\n",
    "\n",
    "def insNormal(x) : \n",
    "    nml = [115,125,135,145]\n",
    "    if x<=nml[0] :\n",
    "        return 0\n",
    "    elif nml[0]<=x and x<=nml[1] :\n",
    "        return (x-nml[0])/(nml[1]-nml[0])\n",
    "    elif nml[1]<=x and x<=nml[2] :\n",
    "        return 1\n",
    "    elif nml[2]<=x and x<=nml[3] :\n",
    "        return (nml[3]-x)/(nml[3]-nml[2])\n",
    "    elif x >= nml[3] :\n",
    "        return 0\n",
    "    \n",
    "def insTinggi(x) : \n",
    "    tgi = [135,145]\n",
    "    if x<=tgi[0] :\n",
    "        return 0\n",
    "    elif tgi[0]<=x and x<=tgi[1] :\n",
    "        return (x-tgi[0])/(tgi[1]-tgi[0])\n",
    "    elif x >= tgi[1] :\n",
    "        return 1\n",
    "\n",
    "def FuzzyInsulin(data) :\n",
    "    ins = data['Insulin']\n",
    "    insulRendah = []\n",
    "    insulNormal = []\n",
    "    insulTinggi = []\n",
    "\n",
    "    for i in ins:\n",
    "        insulRendah.append((insRendah(i)))\n",
    "        insulNormal.append((insNormal(i)))\n",
    "        insulTinggi.append((insTinggi(i)))\n",
    "        \n",
    "    #print(insulRendah[0:5])\n",
    "    #print(insulNormal[0:5])\n",
    "    #print(insulTinggi[0:5])\n",
    "    \n",
    "    fIns = []\n",
    "    for h in range(len(ins)):\n",
    "        if insulRendah[h] > insulNormal[h]:\n",
    "            fIns.append(\"Rendah\")\n",
    "        elif insulNormal[h] > insulTinggi[h]:\n",
    "            fIns.append(\"Normal\")\n",
    "        else:\n",
    "            fIns.append(\"Tinggi\")\n",
    "    \n",
    "    #print(fIns[0:5])\n",
    "    return fIns\n",
    "\n",
    "def bmiRendah(x) : \n",
    "    rdh = [16,21]\n",
    "    if x<=rdh[0] :\n",
    "        return 1\n",
    "    elif rdh[0]<=x and x<=rdh[1] :\n",
    "        return (rdh[1]-x)/(rdh[1]-rdh[0])\n",
    "    elif x >= rdh[1] :\n",
    "        return 0\n",
    "\n",
    "def bmiNormal(x) : \n",
    "    nml = [16,21,22.5,27.5]\n",
    "    if x<=nml[0] :\n",
    "        return 0\n",
    "    elif nml[0]<=x and x<=nml[1] :\n",
    "        return (x-nml[0])/(nml[1]-nml[0])\n",
    "    elif nml[1]<=x and x<=nml[2] :\n",
    "        return 1\n",
    "    elif nml[2]<=x and x<=nml[3] :\n",
    "        return (nml[3]-x)/(nml[3]-nml[2])\n",
    "    elif x >= nml[3] :\n",
    "        return 0\n",
    "    \n",
    "def bmiTinggi(x) : \n",
    "    tgi = [22.5,27.5]\n",
    "    if x<=tgi[0] :\n",
    "        return 0\n",
    "    elif tgi[0]<=x and x<=tgi[1] :\n",
    "        return (x-tgi[0])/(tgi[1]-tgi[0])\n",
    "    elif x >= tgi[1] :\n",
    "        return 1\n",
    "\n",
    "def FuzzyBMI(data) :\n",
    "    bmi = data['BMI']\n",
    "    bRendah = []\n",
    "    bNormal = []\n",
    "    bTinggi = []\n",
    "\n",
    "    for i in bmi:\n",
    "        bRendah.append((bmiRendah(i)))\n",
    "        bNormal.append((bmiNormal(i)))\n",
    "        bTinggi.append((bmiTinggi(i)))\n",
    "        \n",
    "    #print(bRendah[0:5])\n",
    "    #print(bNormal[0:5])\n",
    "    #print(bTinggi[0:5])\n",
    "    \n",
    "    fBMI = []\n",
    "    for h in range(len(bmi)):\n",
    "        if bRendah[h] > bNormal[h]:\n",
    "            fBMI.append(\"Rendah\")\n",
    "        elif bNormal[h] > bTinggi[h]:\n",
    "            fBMI.append(\"Normal\")\n",
    "        else:\n",
    "            fBMI.append(\"Tinggi\")\n",
    "    \n",
    "    #print(fBMI[0:5])\n",
    "    return fBMI\n",
    "\n",
    "def dpfRendah(x) : \n",
    "    rdh = [0.4,0.6]\n",
    "    if x<=rdh[0] :\n",
    "        return 1\n",
    "    elif rdh[0]<=x and x<=rdh[1] :\n",
    "        return (rdh[1]-x)/(rdh[1]-rdh[0])\n",
    "    elif x >= rdh[1] :\n",
    "        return 0\n",
    "\n",
    "def dpfNormal(x) : \n",
    "    nml = [0.4,0.6,0.9,1.1]\n",
    "    if x<=nml[0] :\n",
    "        return 0\n",
    "    elif nml[0]<=x and x<=nml[1] :\n",
    "        return (x-nml[0])/(nml[1]-nml[0])\n",
    "    elif nml[1]<=x and x<=nml[2] :\n",
    "        return 1\n",
    "    elif nml[2]<=x and x<=nml[3] :\n",
    "        return (nml[3]-x)/(nml[3]-nml[2])\n",
    "    elif x >= nml[3] :\n",
    "        return 0\n",
    "    \n",
    "def dpfTinggi(x) : \n",
    "    tgi = [0.9,1.1]\n",
    "    if x<=tgi[0] :\n",
    "        return 0\n",
    "    elif tgi[0]<=x and x<=tgi[1] :\n",
    "        return (x-tgi[0])/(tgi[1]-tgi[0])\n",
    "    elif x >= tgi[1] :\n",
    "        return 1\n",
    "\n",
    "def FuzzyDiabetesPedigreeFunction(data) :\n",
    "    dpf = data['DiabetesPedigreeFunction']\n",
    "    dRendah = []\n",
    "    dNormal = []\n",
    "    dTinggi = []\n",
    "\n",
    "    for i in dpf:\n",
    "        dRendah.append((dpfRendah(i)))\n",
    "        dNormal.append((dpfNormal(i)))\n",
    "        dTinggi.append((dpfTinggi(i)))\n",
    "        \n",
    "    #print(dRendah[0:5])\n",
    "    #print(dNormal[0:5])\n",
    "    #print(dTinggi[0:5])\n",
    "    \n",
    "    fDPF = []\n",
    "    for h in range(len(dpf)):\n",
    "        if dRendah[h] > dNormal[h]:\n",
    "            fDPF.append(\"Rendah\")\n",
    "        elif dNormal[h] > dTinggi[h]:\n",
    "            fDPF.append(\"Normal\")\n",
    "        else:\n",
    "            fDPF.append(\"Tinggi\")\n",
    "    \n",
    "    #print(fDPF[0:5])\n",
    "    return fDPF\n",
    "\n",
    "def ageMuda(x) : \n",
    "    rdh = [15,19]\n",
    "    if x<=rdh[0] :\n",
    "        return 1\n",
    "    elif rdh[0]<=x and x<=rdh[1] :\n",
    "        return (rdh[1]-x)/(rdh[1]-rdh[0])\n",
    "    elif x >= rdh[1] :\n",
    "        return 0\n",
    "\n",
    "def ageDewasa(x) : \n",
    "    nml = [15,19,22,26]\n",
    "    if x<=nml[0] :\n",
    "        return 0\n",
    "    elif nml[0]<=x and x<=nml[1] :\n",
    "        return (x-nml[0])/(nml[1]-nml[0])\n",
    "    elif nml[1]<=x and x<=nml[2] :\n",
    "        return 1\n",
    "    elif nml[2]<=x and x<=nml[3] :\n",
    "        return (nml[3]-x)/(nml[3]-nml[2])\n",
    "    elif x >= nml[3] :\n",
    "        return 0\n",
    "    \n",
    "def ageTua(x) : \n",
    "    tgi = [22,26]\n",
    "    if x<=tgi[0] :\n",
    "        return 0\n",
    "    elif tgi[0]<=x and x<=tgi[1] :\n",
    "        return (x-tgi[0])/(tgi[1]-tgi[0])\n",
    "    elif x >= tgi[1] :\n",
    "        return 1\n",
    "\n",
    "def FuzzyAge(data) :\n",
    "    age = data['Age']\n",
    "    aRendah = []\n",
    "    aNormal = []\n",
    "    aTinggi = []\n",
    "\n",
    "    for i in age:\n",
    "        aRendah.append((ageMuda(i)))\n",
    "        aNormal.append((ageDewasa(i)))\n",
    "        aTinggi.append((ageTua(i)))\n",
    "        \n",
    "    #print(aRendah[0:5])\n",
    "    #print(aNormal[0:5])\n",
    "    #print(aTinggi[0:5])\n",
    "    \n",
    "    fAge = []\n",
    "    for h in range(len(age)):\n",
    "        if aRendah[h] > aNormal[h]:\n",
    "            fAge.append(\"Muda\")\n",
    "        elif aNormal[h] > aTinggi[h]:\n",
    "            fAge.append(\"Dewasa\")\n",
    "        else:\n",
    "            fAge.append(\"Tua\")\n",
    "            \n",
    "    #print(fAge[0:5])\n",
    "    return fAge\n",
    "\n",
    "def MergeFuzzy():\n",
    "    #print(\"Data sebelum pre-process :\\n\", dm.head())\n",
    "    data = imputasiKNN(dataAwal)\n",
    "    #print(\"Data sesudah imputasi KNN :\\n\", data.head())\n",
    "\n",
    "    Pregnancies = pd.DataFrame(FuzzyPregnancies(data), columns = ['Pregnancies'])\n",
    "    Glucose = pd.DataFrame(FuzzyGlucose(data), columns = ['Glucose'])\n",
    "    BloodPressure = pd.DataFrame(FuzzyBloodPressure(data), columns = ['BloodPressure'])\n",
    "    SkinThickness = pd.DataFrame(FuzzySkinThickness(data), columns = ['SkinThickness'])\n",
    "    Insulin = pd.DataFrame(FuzzyInsulin(data), columns = ['Insulin'])\n",
    "    Bmi = pd.DataFrame(FuzzyBMI(data), columns = ['BMI'])\n",
    "    DiabetesPedigreeFunction = pd.DataFrame(FuzzyDiabetesPedigreeFunction(data), columns = ['DiabetesPedigreeFunction'])\n",
    "    Age = pd.DataFrame(FuzzyAge(data), columns = ['Age'])\n",
    "    \n",
    "    result = pd.concat([Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, Bmi, DiabetesPedigreeFunction, Age, data['Outcome']], axis=1)\n",
    "    \n",
    "    #print(\"Data sesudah diskritisasi :\\n\", result.head())\n",
    "    return result\n",
    "    #result.to_csv(\"MergedFuzzy2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MergeFuzzy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3 Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_total_entropy(train_data, label, kelas):\n",
    "    total_baris = train_data.shape[0] #ukuran total dari dataset\n",
    "    total_entropy = 0\n",
    "    \n",
    "    #pengulangan tiap kelas 0 dan 1\n",
    "    for c in kelas: \n",
    "        #jumlah data dari kelas\n",
    "        total_kelas = train_data[train_data[label] == c].shape[0] \n",
    "        #menghitung entropy tiap kelas\n",
    "        total_entropy_kelas = - (total_kelas/total_baris)*np.log2(total_kelas/total_baris) \n",
    "        #menambah var class entropy ke var total entropy dari dataset\n",
    "        total_entropy += total_entropy_kelas \n",
    "    \n",
    "    return total_entropy #mengembalikan nilai total entropy\n",
    "\n",
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    #ukuran dari tiap isi fitur misalkan jumlah value \"rendah\" adalah 100\n",
    "    class_count = feature_value_data.shape[0] \n",
    "    entropy = 0\n",
    "    \n",
    "    for c in class_list:\n",
    "        #jumlah data tiap kelas (0 & 1)\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0] \n",
    "        entropy_class = 0\n",
    "        #mengecek apakah jumlah data di kelas sekarang 0 atau tidak\n",
    "        if label_class_count != 0: \n",
    "            #probabilitas tiap kelas dari tiap value fitur\n",
    "            probability_class = label_class_count/class_count \n",
    "            #menghitung entropy\n",
    "            entropy_class = - probability_class * np.log2(probability_class) \n",
    "        #menambahkan entropy dari tiap kelas ke variabel entropy\n",
    "        entropy += entropy_class \n",
    "    return entropy\n",
    "\n",
    "def calc_info_gain(feature_name, train_data, label, class_list):\n",
    "    #mendapatkan isi dari fitur (ex: rendah, normal, tinggi)\n",
    "    feature_value_list = train_data[feature_name].unique() \n",
    "    #mendapatkan total data\n",
    "    total_row = train_data.shape[0] \n",
    "    feature_info = 0.0\n",
    "    \n",
    "     #perulangan tiap isi dari fitur\n",
    "    for feature_value in feature_value_list:\n",
    "        #memfilter data berdasarkan isi fitur yang looping sekarang\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] \n",
    "        #mendapatkan ukuran dari isi fitur\n",
    "        feature_value_count = feature_value_data.shape[0] \n",
    "        #menghitung entropy dari tiap isi fitur misal Pregnancies (ex: Rendah) entropynya berapa dst\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list)\n",
    "        #probabilitas dari total isi fitur dengan total keseluruhan data \n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        #menghitung nilai informasi dari tiap isi fitur dan memasukannya ke dalam variabel feature_info\n",
    "        feature_info += feature_value_probability * feature_value_entropy \n",
    "    \n",
    "    #menghitung information gain dengan cara total entropy dikurangi nilai feature_info\n",
    "    return calc_total_entropy(train_data, label, class_list) - feature_info \n",
    "\n",
    "def find_most_informative_feature(train_data, label, class_list):\n",
    "    #mendapatkan nama tiap fitur dalam dataset\n",
    "    feature_list = train_data.columns.drop(label) \n",
    "    #N.B. label bukan merupakan fitur, maka kita drop\n",
    "\n",
    "    max_info_gain = -1\n",
    "    max_info_feature = None\n",
    "    \n",
    "    #looping tiap fitur dalam dataset\n",
    "    for feature in feature_list: \n",
    "        #calc_info_gain(\"Pregnancies\", data training, \"Outcome\", [0,1])\n",
    "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list) \n",
    "        #pengecekan apakah info gain bernilai 0\n",
    "        if feature_info_gain == 0 : \n",
    "            #jika iya maka nilai info gain akan diganti menjadi -1 sehingga tidak menjadi info gain terbesar\n",
    "            feature_info_gain = -1 \n",
    "        #memilih nilai information gain terbesar\n",
    "        if max_info_gain < feature_info_gain: \n",
    "            max_info_gain = feature_info_gain\n",
    "            max_info_feature = feature\n",
    "            \n",
    "    return max_info_feature\n",
    "\n",
    "def generate_sub_tree(feature_name, train_data, label, class_list, cek=None):\n",
    "    #mengecek apakah fitur yang sekarang di cek berisi None\n",
    "    if feature_name==None:\n",
    "        feature_name=cek\n",
    "        #print(cek)\n",
    "    \n",
    "    #print(\"--> generate_sub_tree <--\")\n",
    "    #print(\"label :\",label)\n",
    "    #print(\"class_list :\",class_list)\n",
    "\n",
    "    #mendapatkan jumlah tiap isi dari fitur (ex: glucose rendah 5, normal 10, tinggi 5)\n",
    "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False) \n",
    "    #print(\"feature_value_count_dict :\\n\", feature_value_count_dict)\n",
    "    #print(\"\")\n",
    "    \n",
    "    f_left=8\n",
    "    l_node=False\n",
    "    \n",
    "    cf= ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction','Age']\n",
    "    #cek sisa fitur\n",
    "    for f in cf: \n",
    "        #print(train_data[f].unique(),f)\n",
    "        panj = len(train_data[f].unique())\n",
    "        if panj == 1:\n",
    "            f_left-=1\n",
    "    if f_left<=1:\n",
    "        l_node=True\n",
    "    #print(l_node,f_left)\n",
    "\n",
    "    tree = {} #tree\n",
    "    #print(\"Tree :\\n\", tree)\n",
    "    cek_fitur = cek\n",
    "    #print(\"Cek_fitur :\", cek_fitur)\n",
    "\n",
    "    #melakukan perulangan dari tiap isi dari fitur (ex : rendah 5, normal 10, tinggi 5)\n",
    "    for feature_value, count in feature_value_count_dict.iteritems(): \n",
    "        # print(\"\")\n",
    "        # print(\"feature_value :\", feature_value)\n",
    "        # print(\"count :\", count)\n",
    "        # filter dataset sesuai dengan yang dilooping sekarang (ex : glucose rendah)\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] \n",
    "        #print(\"feature_value_data :\\n\", pd.DataFrame(feature_value_data).head())\n",
    "        \n",
    "        # variabel untuk melakukan pengecekan apakah kelas sudah harus berehenti atau tidak\n",
    "        assigned_to_node = False \n",
    "        cek_count = []\n",
    "        cek_class = []\n",
    "\n",
    "        for cek in class_list:\n",
    "            # menghitung jumlah tiap kelas\n",
    "            class_count = feature_value_data[feature_value_data[label] == cek].shape[0] \n",
    "            cek_count.append(class_count)\n",
    "            cek_class.append(cek)\n",
    "        \n",
    "        #print(\"cek class :\", cek_class, type(cek_class[0]))\n",
    "        #print(\"cek count :\", cek_count, type(cek_count[0]))\n",
    "\n",
    "        for c in class_list: #looping tiap kelas\n",
    "            #print(\"c :\", c, type(c))\n",
    "            # menghitung jumlah tiap kelas\n",
    "            class_count = feature_value_data[feature_value_data[label] == c].shape[0] \n",
    "            # print(\"Jumlah kelas\",c,\"adalah\",class_count)\n",
    "\n",
    "            if l_node ==True:\n",
    "                if cek_count[1] > cek_count[0] :\n",
    "                    #menambahkan node ke tree\n",
    "                    tree[feature_value] = float(cek_class[1]) \n",
    "                    #print(\"tree[feature_value] :\", tree[feature_value])\n",
    "                    #menghilangkan baris sesuai dengan looping dari isi fitur (ex : glucose normal)\n",
    "                    train_data = train_data[train_data[feature_name] != feature_value] \n",
    "                    #print(\"Train Data gen:\\n\", train_data.head())\n",
    "                    assigned_to_node = True\n",
    "                else : \n",
    "                    #menambahkan node ke tree\n",
    "                    tree[feature_value] = float(cek_class[0]) \n",
    "                    #print(\"tree[feature_value] :\", tree[feature_value])\n",
    "                    #menghilangkan baris sesuai dengan looping dari isi fitur (ex : glucose normal)\n",
    "                    train_data = train_data[train_data[feature_name] != feature_value] \n",
    "                    #print(\"Train Data gen:\\n\", train_data.head())\n",
    "                    assigned_to_node = True\n",
    "            elif cek_fitur != feature_name : #tambahan pengecekan\n",
    "                # jumlah dari isi fitur pada tiap kelas (0/1) == jumlah kelas dari total kelas \n",
    "                if class_count == count: \n",
    "                    #menambahkan node ke tree\n",
    "                    tree[feature_value] = c \n",
    "                    #print(\"tree[feature_value] :\", tree[feature_value])\n",
    "                    #menghilangkan baris sesuai dengan looping dari isi fitur (ex : glucose normal)\n",
    "                    train_data = train_data[train_data[feature_name] != feature_value] \n",
    "                    #print(\"Train Data gen:\\n\", train_data.head())\n",
    "                    assigned_to_node = True\n",
    "            elif cek_fitur == feature_name : #tambahan pengecekan\n",
    "                if cek_count[1] > cek_count[0] :\n",
    "                    #menambahkan node ke tree\n",
    "                    tree[feature_value] = float(cek_class[1]) \n",
    "                    #print(\"tree[feature_value] :\", tree[feature_value])\n",
    "                    #menghilangkan baris sesuai dengan looping dari isi fitur (ex : glucose normal)\n",
    "                    train_data = train_data[train_data[feature_name] != feature_value] \n",
    "                    #print(\"Train Data gen:\\n\", train_data.head())\n",
    "                    assigned_to_node = True\n",
    "                else : \n",
    "                    #menambahkan node ke tree\n",
    "                    tree[feature_value] = float(cek_class[0]) \n",
    "                    #print(\"tree[feature_value] :\", tree[feature_value])\n",
    "                    #menghilangkan baris sesuai dengan looping dari isi fitur (ex : glucose normal)\n",
    "                    train_data = train_data[train_data[feature_name] != feature_value] \n",
    "                    #print(\"Train Data gen:\\n\", train_data.head())\n",
    "                    assigned_to_node = True\n",
    "        #pengecekan apabila jumlah dari tiap kelas masih ada atau belum bisa ditentukan berhenti atau tidak di (0/1)\n",
    "        if not assigned_to_node: \n",
    "            #karena masih belum bisa ditentukan, maka diberi tanda ? (ex : rendah ?)\n",
    "            tree[feature_value] = \"?\" \n",
    "    \n",
    "    #cek_fitur = feature_name\n",
    "    #print(\"Tree :\", tree)\n",
    "    #print(\"\")\n",
    "    return tree, train_data\n",
    "\n",
    "def make_tree(root, prev_feature_value, train_data, label, class_list, cek_fitur=None):\n",
    "    #print(\"\")\n",
    "    #print(\"---> make root function <---\")\n",
    "    #print(\"prev_feature_value :\", prev_feature_value)\n",
    "    \n",
    "    #pengecekan apabila dataset tidak berjumlah 0\n",
    "    if train_data.shape[0] != 0: \n",
    "        #print(\"train data shape :\", train_data.shape[0])\n",
    "        #menemukan fitur yang memiliki information gain terbesar\n",
    "        max_info_feature = find_most_informative_feature(train_data, label, class_list) \n",
    "        #print(\"___________________________________________________\")\n",
    "        #print(\"Max_info_feature :\",  max_info_feature)\n",
    "        #print(\"train data :\", train_data)\n",
    "        #mendapatkan simpil pohon dan update dataset\n",
    "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list, cek_fitur) \n",
    "        #print(\"Cek fitur sebelumnya :\", cek_fitur) \n",
    "        # print(\"Tree :\", tree)\n",
    "        #print(\"Tree :\", tree)\n",
    "        #print(\"Train data:\\n\", train_data)\n",
    "        next_root = None\n",
    "        \n",
    "        #pengecekan apabila nilai information gain sama semua\n",
    "        if max_info_feature == None : \n",
    "            #print('make_tree', cek_fitur)\n",
    "            #menggunakan fitur sebelumnya\n",
    "            max_info_feature=cek_fitur \n",
    "\n",
    "        #menambahkan simpul ke dalam tree\n",
    "        if prev_feature_value != None: \n",
    "            root[prev_feature_value] = dict()\n",
    "            #print(\"if root[prev_feature_value] :\", root[prev_feature_value])\n",
    "            #menambahkan simpul ke max info gain\n",
    "            root[prev_feature_value][max_info_feature] = tree \n",
    "            # print(\"root prev v :\", root[prev_feature_value][max_info_feature])\n",
    "            #simpul tadi digunakan untuk berlanjut ke simpul tree selanjutnya\n",
    "            next_root = root[prev_feature_value][max_info_feature] \n",
    "            #print(\"if next root:\", next_root)\n",
    "         #menambahkan simpul root ke tree\n",
    "        else:\n",
    "            #print(\"add to root\")\n",
    "            #menambahkan cabang ke atribut yang menjadi akar\n",
    "            root[max_info_feature] = tree \n",
    "            # print(\"Root awal :\", root[max_info_feature])\n",
    "            #simpul tree tadi digunakan untuk lanjut ke simpul selanjutnya\n",
    "            next_root = root[max_info_feature] \n",
    "            #print(\"else next root:\", next_root)\n",
    "        \n",
    "        #looping untuk cabang yang masih bisa diisi cabang baru\n",
    "        for node, branch in list(next_root.items()): \n",
    "            #pengecekan apabila tree masih bisa diisi\n",
    "            if branch == \"?\":\n",
    "                #print(\"Max Info :\", max_info_feature, \"\\nNode :\", node, \"\\nBranch :\", branch)\n",
    "                #update dataset sesuai dengan simpul yang masih bisa diisi. \n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node] \n",
    "                #print(feature_value_data)\n",
    "                cek_fitur = max_info_feature\n",
    "                #print(\"Cek fitur sekarang :\", cek_fitur)\n",
    "                #recursif dengan data yang sudah diupdate\n",
    "                make_tree(next_root, node, feature_value_data, label, class_list, cek_fitur) \n",
    "\n",
    "\n",
    "def id3(train_data_m, label):\n",
    "    #print(\"id3\")\n",
    "    train_data = train_data_m.copy() #mendapatkan salinan dataset\n",
    "    tree = {} #untuk menampung tree\n",
    "    list_kelas = train_data[label].unique() #mendapatkan isi kelas Outcome [0,1]\n",
    "    #print(\"class list :\", list_kelas)\n",
    "    make_tree(tree, None, train_data_m, label, list_kelas) #memulai rekursif\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pengujian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, data_cek):\n",
    "    if not isinstance(tree, dict): #pengecekan jika tree sudah sampai leaf node\n",
    "        return tree #return the value\n",
    "    else:\n",
    "        #print(\"tree :\", tree)\n",
    "        root_node = next(iter(tree)) #mendapatkan fitur pertama dari tree (ex: Glucose)\n",
    "        #print(\"root node :\", next(iter(tree)))\n",
    "        isi_fitur = data_cek[root_node] #mendapatkan isi fitur dari data test sesuai dengan pengecekan atribut pertama sebelumnya\n",
    "        #print(\"feature value :\", instance[root_node])\n",
    "        if isi_fitur in tree[root_node]: #mengecek apakah isi fitur sekarang ada di root sekarang\n",
    "            #print(\"Cek :\",tree[root_node][feature_value])\n",
    "            return predict(tree[root_node][isi_fitur], data_cek) #lanjut ke fitur selanjutnya\n",
    "        else:\n",
    "            return 0 \n",
    "\n",
    "def evaluate(tree, test_data_m):\n",
    "    #correct_preditct = 0\n",
    "    #wrong_preditct = 0\n",
    "    hasil_prediksi = []\n",
    "    for i in range (len(test_data_m)): #looping per data test\n",
    "        #print(\"index :\", i)\n",
    "        #print(\"Data yang di uji sekarang :\\n\", pd.DataFrame(test_data_m.iloc[index]))\n",
    "        #print(\"test_data_m.iloc[index] :\", test_data_m.iloc[i])\n",
    "        result = predict(tree, test_data_m.iloc[i]) #memprediksi baris yang looping sekarang\n",
    "        #print(\"Hasil prediksi :\", result)\n",
    "        #print(\"\")\n",
    "        hasil_prediksi.append(result) #mendapatkan hasil prediksi dari data yang diuji\n",
    "        #print(\"Hasil prediksinya adalah :\",result)\n",
    "\n",
    "    return hasil_prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(t,s):\n",
    "    if not isinstance(t,dict) and not isinstance(t,list):\n",
    "        print(\"\\t\"*s+str(t))\n",
    "    else:\n",
    "        for key in t:\n",
    "            print(\"\\t\"*s+str(key))\n",
    "            if not isinstance(t,list):\n",
    "                formatData(t[key],s+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data setelah pre processing :\n",
      "   Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "0      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "1      Rendah  Rendah        Normal        Tinggi  Rendah  Tinggi   \n",
      "2      Tinggi  Normal        Normal        Tinggi  Tinggi  Normal   \n",
      "3      Rendah  Rendah        Normal        Normal  Rendah  Tinggi   \n",
      "4      Rendah  Rendah        Rendah        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "  DiabetesPedigreeFunction     Age  Outcome  \n",
      "0                   Normal     Tua      1.0  \n",
      "1                   Rendah     Tua      0.0  \n",
      "2                   Normal     Tua      1.0  \n",
      "3                   Rendah  Dewasa      0.0  \n",
      "4                   Tinggi     Tua      1.0  \n"
     ]
    }
   ],
   "source": [
    "dm = MergeFuzzy()\n",
    "print(\"Data setelah pre processing :\\n\",dm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFold():\n",
    "    dataset = dm # mengambil dataset\n",
    "    k = 10 # menentukan nilai k\n",
    "\n",
    "    dataPos = dm[dm['Outcome'] == 1]\n",
    "    dataNeg = dm[dm['Outcome'] == 0]\n",
    "\n",
    "    kPos = []\n",
    "    kNeg = []\n",
    "\n",
    "    fold = [] # membuat list untuk menampung data yang sudah dipecah\n",
    "    for q in range(k): #looping sesuai dengan k yang telah ditentukan\n",
    "        # mengambil 10% data dan memasukkannya ke dalam list 'fold'\n",
    "        kPos.append(pd.DataFrame(dataPos[round((dataPos.shape[0]/k)*q):round((dataPos.shape[0]/k)*(q+1))]))\n",
    "        kNeg.append(pd.DataFrame(dataNeg[round((dataNeg.shape[0]/k)*q):round((dataNeg.shape[0]/k)*(q+1))]))\n",
    "        #print(dataset[round((dataset.shape[0]/10)*q):round((dataset.shape[0]/10)*(q+1))])\n",
    "\n",
    "    for j in range(k):\n",
    "        fold.append(pd.concat([kPos[j],kNeg[j]]))\n",
    "\n",
    "    return fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregatting(tree, test_data, k):\n",
    "\n",
    "    hasil_prediksi = []\n",
    "    has_tree = tree\n",
    "    test_data = test_data\n",
    "    k = k\n",
    "\n",
    "    #melakukan pengujian terhadap k tree bootstrap sehingga menghasilkan k prediksi \n",
    "    for i in range(k):\n",
    "        #print(\"Prediksi sebelum aggregat yang ke :\", i+1)\n",
    "        prediksi = evaluate(has_tree[i], test_data)\n",
    "        hasil_prediksi.append(pd.DataFrame(prediksi, columns=['Pred'+str(i+1)]))\n",
    "\n",
    "    hasil_prediksi = pd.concat(hasil_prediksi, axis=1)\n",
    "    print(hasil_prediksi)\n",
    "    \n",
    "    prediksi_final = []\n",
    "    #hasil_prediksi = 77\n",
    "    for i in range (len(hasil_prediksi)) :\n",
    "        temp_pred = []\n",
    "        temp_class = []\n",
    "        countHas = hasil_prediksi.loc[i].value_counts() #mendapatkan nilai 0 dan 1 beserta jumlahnya\n",
    "        #print(countHas)\n",
    "        #print(len(hasil_prediksi))\n",
    "        #print(\"Looping data indek ke:\", i)\n",
    "        for feature_value, count in countHas.iteritems(): #memisahkan nilai 0 dan 1 beserta jumlahnya\n",
    "            temp_pred.append(count) #jumlah 0 atau 1\n",
    "            temp_class.append(feature_value) #[0,1]\n",
    "        \n",
    "        #print(\"temp pred :\", temp_pred)\n",
    "        #print(\"temp class :\", temp_class)\n",
    "\n",
    "        #melakukan pemilihan jumlah terbesar dari 0 atau 1\n",
    "        #jika temp_class adalah 2 (berisi 2 angka 0 dan 1) maka masuk ke percabangan lagi\n",
    "        #dan melakukan perbandingan dari jumlah data 0 dan 1. Jumlah terbesar menjadi hasil prediksi akhir\n",
    "        #jika temp_class berisi 1 angka (0 atau 1) maka langsung dipilih karena tidak ada yang dibandingkan\n",
    "        if len(temp_class) == 2 :\n",
    "            if temp_pred[0] > temp_pred[1]:\n",
    "                prediksi_final.append(temp_class[0])\n",
    "            else :\n",
    "                prediksi_final.append(temp_class[1])\n",
    "        elif len(temp_class) == 1 :\n",
    "            prediksi_final.append(temp_class[0])\n",
    "        #else : \n",
    "        #    prediksi_final.append(0.0)\n",
    "    \n",
    "    return prediksi_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3bagging():\n",
    "    fold = kFold() # mengambil data yang sudah dibagi menjadi 10 bagian\n",
    "    k = [i for i in range(10)] # membuat list berisi angka 0-9\n",
    "    \n",
    "    #data_bootstrap = []\n",
    "    prediksi_final = []\n",
    "    akurasi = []\n",
    "    presisi = []\n",
    "    recall = []\n",
    "    for i in k:\n",
    "        #''' SPLIT TRAIN TEST '''\n",
    "        Test = fold[k[i]] #misalkan looping ke 0, maka fold[0] menjadi data test dst\n",
    "        y_test = Test['Outcome']\n",
    "        #print(\"Panjang data testing :\", len(Test), \"data\")\n",
    "        #print(\"Testing bagian ke:\", i, \"\\n\", Test)\n",
    "        #print(\"\")\n",
    "\n",
    "        temp = k[:i]+k[i+1:] #misalkan looping ke 0, maka fold selain 0 akan menjadi data train\n",
    "        Train = pd.concat([fold[y] for y in temp])\n",
    "        #print(\"Panjang data training :\", len(Train), \"data\")\n",
    "        #print(\"Training bagian ke:\", temp, \"\\n\", Train)\n",
    "\n",
    "        #''' BOOTSTRAP '''\n",
    "        bootstrap = []\n",
    "        #melakukan bootstrap data dengan cara meresampling data train yang diuji sekarang. Bootstrap dilakukan sebanyak k\n",
    "        for j in range(len(k)):\n",
    "            bootstrap.append(Train.sample(n=len(Train), replace=True, random_state=2)) #2,6,11,39,40,\n",
    "        #print(\"Jumlah data Bootstrap :\", len(bootstrap))\n",
    "        #print(\"\")\n",
    "        #data_bootstrap.append(bootstrap)\n",
    "\n",
    "        tree = []\n",
    "        #melakukan pembuatan tree menggunakan sejumlak k data bootstrap\n",
    "        for bs in range(len(bootstrap)):\n",
    "            temp_tree = None\n",
    "            temp_tree = id3(bootstrap[bs], 'Outcome')\n",
    "            tree.append(temp_tree)\n",
    "\n",
    "        print(\"Fold yang ke\",i+1,\"dengan data bootstrap berjumlah :\", len(bootstrap))\n",
    "        print(\"Menghasilkan tree berjumlah :\", len(tree))\n",
    "        print(\"Data yang akan diuji sebagai berikut :\\n\", pd.DataFrame(Test).head())\n",
    "        print(\"Panjang data test :\", pd.DataFrame(Test).shape[0])\n",
    "        print(\"Panjang data train :\", pd.DataFrame(Train).shape[0])\n",
    "\n",
    "        #melakukan aggregatting terhadap k hasil prediksi menggunakan aturan majority vote\n",
    "        y_pred = pd.DataFrame(aggregatting(tree, Test, len(k)), columns=['P'+str(i+1)])\n",
    "        print(\"y_pred :\\n\", y_pred)\n",
    "        prediksi_final.append(y_pred)\n",
    "\n",
    "        accuracy, pres, rec = performa(y_test, y_pred) #penghitungan performa dari hasil prediksi\n",
    "        akurasi.append(accuracy)\n",
    "        presisi.append(pres)\n",
    "        recall.append(rec)\n",
    "\n",
    "    prediksi_final = pd.concat(prediksi_final, axis=1)\n",
    "    \n",
    "    return prediksi_final, akurasi, presisi, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3biasa():\n",
    "    fold = kFold() # mengambil data yang sudah dibagi menjadi 10 bagian\n",
    "    k = [i for i in range(10)] # membuat list berisi angka 0-9\n",
    "    \n",
    "    #data_bootstrap = []\n",
    "    prediksi_final = []\n",
    "    akurasi = []\n",
    "    presisi = []\n",
    "    recall = []\n",
    "    for i in k:\n",
    "        #''' SPLIT TRAIN TEST '''\n",
    "        Test = fold[k[i]] #misalkan looping ke 0, maka fold[0] menjadi data test dst\n",
    "        y_test = Test['Outcome']\n",
    "        #print(\"Panjang data testing :\", len(Test), \"data\")\n",
    "        #print(\"Testing bagian ke:\", i, \"\\n\", Test)\n",
    "        #print(\"\")\n",
    "\n",
    "        temp = k[:i]+k[i+1:] #misalkan looping ke 0, maka fold selain 0 akan menjadi data train\n",
    "        Train = pd.concat([fold[y] for y in temp])\n",
    "        #print(\"Panjang data training :\", len(Train), \"data\")\n",
    "        #print(\"Training bagian ke:\", temp, \"\\n\", Train)\n",
    "\n",
    "        tree = id3(Train, 'Outcome') #memulai membuat tree menggunakan algoritma ID3\n",
    "        #print(\"tree :\\n\", tree)\n",
    "\n",
    "        #formatData(tree,0) #mencetak tree\n",
    "\n",
    "        print(\"Fold yang ke\",i+1,\"dengan data training berjumlah :\", len(Train))\n",
    "        print(\"Data yang akan diuji sebagai berikut :\\n\", pd.DataFrame(Test).head())\n",
    "        print(\"Panjang data test :\", pd.DataFrame(Test).shape[0])\n",
    "        print(\"Panjang data train :\", pd.DataFrame(Train).shape[0])\n",
    "\n",
    "        y_pred = evaluate(tree, Test) #melakukan pengujian terhadap tree menggunakan data test ==> [0,1,0,1,dst]\n",
    "        #print(\"y_temp :\\n\", y_temp)\n",
    "        \n",
    "        print(\"y_pred :\\n\", y_pred)\n",
    "        prediksi_final.append(pd.DataFrame(y_pred, columns=['P'+str(i+1)]))\n",
    "\n",
    "\n",
    "        accuracy, pres, rec = performa(y_test, y_pred) #menghitung performa dari tree yg diuji sekarang\n",
    "        akurasi.append(accuracy)\n",
    "        presisi.append(pres)\n",
    "        recall.append(rec)\n",
    "\n",
    "    prediksi_final = pd.concat(prediksi_final, axis=1)\n",
    "    \n",
    "    return prediksi_final, akurasi, presisi, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performa(y_test, y_pred):\n",
    "    #confusion matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "    print('Confusion matrix : \\n',matrix)\n",
    "    print(\"\")\n",
    "\n",
    "    # outcome values order in sklearn\n",
    "    tp, fn, fp, tn = confusion_matrix(y_test, y_pred,labels=[1,0]).reshape(-1)\n",
    "    print(\"True positive :\", tp)\n",
    "    print(\"False negative :\", fn)\n",
    "    print(\"False positive :\", fp)\n",
    "    print(\"True negative :\", tn)\n",
    "    print(\"\")\n",
    "\n",
    "    # classification report for precision, recall f1-score and accuracy\n",
    "    matrix = classification_report(y_test, y_pred,labels=[1,0])\n",
    "    print('Classification report : \\n',matrix)\n",
    "    print(\"\")\n",
    "\n",
    "    #akurasi\n",
    "    # accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "    # print(\"Akurasi fold ini adalah :\", accuracy, \" %\")\n",
    "    accuracy2 = round(((tp+tn)/(tp+fn+fp+tn)*100), 2)\n",
    "    presisi = round(((tp/(tp+fp))*100),2)\n",
    "    recall = round(((tp/(tp+fn))*100),2)\n",
    "    print(\"Akurasi fold ini adalah :\", accuracy2, \" %\")\n",
    "    print(\"Presisi fold ini adalah :\", presisi, \" %\")\n",
    "    print(\"Recall fold ini adalah :\", recall, \" %\")\n",
    "    print(\"===========================================================\")\n",
    "\n",
    "    return accuracy2, presisi, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold yang ke 1 dengan data bootstrap berjumlah : 10\n",
      "Menghasilkan tree berjumlah : 10\n",
      "Data yang akan diuji sebagai berikut :\n",
      "   Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "0      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "2      Tinggi  Normal        Normal        Tinggi  Tinggi  Normal   \n",
      "4      Rendah  Rendah        Rendah        Tinggi  Tinggi  Tinggi   \n",
      "6      Normal  Rendah        Rendah        Tinggi  Rendah  Tinggi   \n",
      "8      Normal  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "  DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                   Normal  Tua      1.0  \n",
      "2                   Normal  Tua      1.0  \n",
      "4                   Tinggi  Tua      1.0  \n",
      "6                   Rendah  Tua      1.0  \n",
      "8                   Rendah  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "    Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9  Pred10\n",
      "0     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "1     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "2     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "3     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "4     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
      "72    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "73    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "74    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "75    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "76    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "\n",
      "[77 rows x 10 columns]\n",
      "y_pred :\n",
      "      P1\n",
      "0   1.0\n",
      "1   1.0\n",
      "2   1.0\n",
      "3   0.0\n",
      "4   1.0\n",
      "..  ...\n",
      "72  0.0\n",
      "73  0.0\n",
      "74  0.0\n",
      "75  0.0\n",
      "76  0.0\n",
      "\n",
      "[77 rows x 1 columns]\n",
      "Confusion matrix : \n",
      " [[18  9]\n",
      " [13 37]]\n",
      "\n",
      "True positive : 18\n",
      "False negative : 9\n",
      "False positive : 13\n",
      "True negative : 37\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.67      0.62        27\n",
      "           0       0.80      0.74      0.77        50\n",
      "\n",
      "    accuracy                           0.71        77\n",
      "   macro avg       0.69      0.70      0.70        77\n",
      "weighted avg       0.73      0.71      0.72        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 71.43  %\n",
      "Presisi fold ini adalah : 58.06  %\n",
      "Recall fold ini adalah : 66.67  %\n",
      "===========================================================\n",
      "Fold yang ke 2 dengan data bootstrap berjumlah : 10\n",
      "Menghasilkan tree berjumlah : 10\n",
      "Data yang akan diuji sebagai berikut :\n",
      "    Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "61      Tinggi  Rendah        Normal        Tinggi  Normal  Tinggi   \n",
      "64      Tinggi  Rendah        Normal        Normal  Tinggi  Tinggi   \n",
      "66      Rendah  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "70      Normal  Rendah        Normal        Normal  Rendah  Tinggi   \n",
      "72      Tinggi  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "61                   Rendah  Tua      1.0  \n",
      "64                   Rendah  Tua      1.0  \n",
      "66                   Normal  Tua      1.0  \n",
      "70                   Normal  Tua      1.0  \n",
      "72                   Normal  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "    Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9  Pred10\n",
      "0     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "1     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "2     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "3     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "4     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
      "72    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "73    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "74    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "75    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "76    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "\n",
      "[77 rows x 10 columns]\n",
      "y_pred :\n",
      "      P2\n",
      "0   0.0\n",
      "1   1.0\n",
      "2   0.0\n",
      "3   0.0\n",
      "4   1.0\n",
      "..  ...\n",
      "72  0.0\n",
      "73  0.0\n",
      "74  0.0\n",
      "75  0.0\n",
      "76  0.0\n",
      "\n",
      "[77 rows x 1 columns]\n",
      "Confusion matrix : \n",
      " [[14 13]\n",
      " [ 7 43]]\n",
      "\n",
      "True positive : 14\n",
      "False negative : 13\n",
      "False positive : 7\n",
      "True negative : 43\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.52      0.58        27\n",
      "           0       0.77      0.86      0.81        50\n",
      "\n",
      "    accuracy                           0.74        77\n",
      "   macro avg       0.72      0.69      0.70        77\n",
      "weighted avg       0.73      0.74      0.73        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 74.03  %\n",
      "Presisi fold ini adalah : 66.67  %\n",
      "Recall fold ini adalah : 51.85  %\n",
      "===========================================================\n",
      "Fold yang ke 3 dengan data bootstrap berjumlah : 10\n",
      "Menghasilkan tree berjumlah : 10\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "154      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "155      Tinggi  Normal        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "159      Tinggi  Normal        Normal        Tinggi  Rendah  Tinggi   \n",
      "164      Rendah  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "165      Tinggi  Rendah        Normal        Normal  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction  Age  Outcome  \n",
      "154                   Rendah  Tua      1.0  \n",
      "155                   Rendah  Tua      1.0  \n",
      "159                   Normal  Tua      1.0  \n",
      "164                   Normal  Tua      1.0  \n",
      "165                   Normal  Tua      1.0  \n",
      "Panjang data test : 76\n",
      "Panjang data train : 692\n",
      "    Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9  Pred10\n",
      "0     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "1     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "2     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "3     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "4     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
      "71    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "72    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "73    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "74    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "75    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "\n",
      "[76 rows x 10 columns]\n",
      "y_pred :\n",
      "      P3\n",
      "0   1.0\n",
      "1   1.0\n",
      "2   1.0\n",
      "3   1.0\n",
      "4   1.0\n",
      "..  ...\n",
      "71  0.0\n",
      "72  0.0\n",
      "73  0.0\n",
      "74  0.0\n",
      "75  1.0\n",
      "\n",
      "[76 rows x 1 columns]\n",
      "Confusion matrix : \n",
      " [[21  5]\n",
      " [10 40]]\n",
      "\n",
      "True positive : 21\n",
      "False negative : 5\n",
      "False positive : 10\n",
      "True negative : 40\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.81      0.74        26\n",
      "           0       0.89      0.80      0.84        50\n",
      "\n",
      "    accuracy                           0.80        76\n",
      "   macro avg       0.78      0.80      0.79        76\n",
      "weighted avg       0.82      0.80      0.81        76\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 80.26  %\n",
      "Presisi fold ini adalah : 67.74  %\n",
      "Recall fold ini adalah : 80.77  %\n",
      "===========================================================\n",
      "Fold yang ke 4 dengan data bootstrap berjumlah : 10\n",
      "Menghasilkan tree berjumlah : 10\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "215      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "216      Tinggi  Rendah        Normal        Tinggi  Normal  Tinggi   \n",
      "218      Tinggi  Rendah        Normal        Normal  Normal  Tinggi   \n",
      "219      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "220      Rendah  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction     Age  Outcome  \n",
      "215                   Normal     Tua      1.0  \n",
      "216                   Normal     Tua      1.0  \n",
      "218                   Tinggi     Tua      1.0  \n",
      "219                   Rendah     Tua      1.0  \n",
      "220                   Tinggi  Dewasa      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "    Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9  Pred10\n",
      "0     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "1     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "2     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "3     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "4     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
      "72    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "73    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "74    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "75    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "76    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "\n",
      "[77 rows x 10 columns]\n",
      "y_pred :\n",
      "      P4\n",
      "0   0.0\n",
      "1   1.0\n",
      "2   0.0\n",
      "3   0.0\n",
      "4   1.0\n",
      "..  ...\n",
      "72  0.0\n",
      "73  0.0\n",
      "74  1.0\n",
      "75  0.0\n",
      "76  1.0\n",
      "\n",
      "[77 rows x 1 columns]\n",
      "Confusion matrix : \n",
      " [[15 12]\n",
      " [12 38]]\n",
      "\n",
      "True positive : 15\n",
      "False negative : 12\n",
      "False positive : 12\n",
      "True negative : 38\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.56      0.56        27\n",
      "           0       0.76      0.76      0.76        50\n",
      "\n",
      "    accuracy                           0.69        77\n",
      "   macro avg       0.66      0.66      0.66        77\n",
      "weighted avg       0.69      0.69      0.69        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 68.83  %\n",
      "Presisi fold ini adalah : 55.56  %\n",
      "Recall fold ini adalah : 55.56  %\n",
      "===========================================================\n",
      "Fold yang ke 5 dengan data bootstrap berjumlah : 10\n",
      "Menghasilkan tree berjumlah : 10\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "284      Normal  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "287      Rendah  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "291      Rendah  Rendah        Normal        Tinggi  Rendah  Tinggi   \n",
      "292      Normal  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "293      Rendah  Rendah        Rendah        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction  Age  Outcome  \n",
      "284                   Rendah  Tua      1.0  \n",
      "287                   Normal  Tua      1.0  \n",
      "291                   Normal  Tua      1.0  \n",
      "292                   Tinggi  Tua      1.0  \n",
      "293                   Normal  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "    Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9  Pred10\n",
      "0     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "1     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "2     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "3     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "4     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
      "72    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "73    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "74    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "75    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "76    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "\n",
      "[77 rows x 10 columns]\n",
      "y_pred :\n",
      "      P5\n",
      "0   1.0\n",
      "1   1.0\n",
      "2   1.0\n",
      "3   1.0\n",
      "4   0.0\n",
      "..  ...\n",
      "72  1.0\n",
      "73  0.0\n",
      "74  0.0\n",
      "75  1.0\n",
      "76  0.0\n",
      "\n",
      "[77 rows x 1 columns]\n",
      "Confusion matrix : \n",
      " [[17 10]\n",
      " [10 40]]\n",
      "\n",
      "True positive : 17\n",
      "False negative : 10\n",
      "False positive : 10\n",
      "True negative : 40\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.63      0.63        27\n",
      "           0       0.80      0.80      0.80        50\n",
      "\n",
      "    accuracy                           0.74        77\n",
      "   macro avg       0.71      0.71      0.71        77\n",
      "weighted avg       0.74      0.74      0.74        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 74.03  %\n",
      "Presisi fold ini adalah : 62.96  %\n",
      "Recall fold ini adalah : 62.96  %\n",
      "===========================================================\n",
      "Fold yang ke 6 dengan data bootstrap berjumlah : 10\n",
      "Menghasilkan tree berjumlah : 10\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "355      Tinggi  Normal        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "356      Rendah  Rendah        Rendah        Tinggi  Tinggi  Tinggi   \n",
      "357      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "359      Rendah  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "360      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction  Age  Outcome  \n",
      "355                   Rendah  Tua      1.0  \n",
      "356                   Normal  Tua      1.0  \n",
      "357                   Normal  Tua      1.0  \n",
      "359                   Normal  Tua      1.0  \n",
      "360                   Normal  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "    Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9  Pred10\n",
      "0     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "1     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "2     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "3     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "4     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
      "72    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "73    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "74    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "75    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "76    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "\n",
      "[77 rows x 10 columns]\n",
      "y_pred :\n",
      "      P6\n",
      "0   1.0\n",
      "1   0.0\n",
      "2   1.0\n",
      "3   1.0\n",
      "4   1.0\n",
      "..  ...\n",
      "72  0.0\n",
      "73  0.0\n",
      "74  0.0\n",
      "75  0.0\n",
      "76  1.0\n",
      "\n",
      "[77 rows x 1 columns]\n",
      "Confusion matrix : \n",
      " [[18  9]\n",
      " [ 9 41]]\n",
      "\n",
      "True positive : 18\n",
      "False negative : 9\n",
      "False positive : 9\n",
      "True negative : 41\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.67      0.67        27\n",
      "           0       0.82      0.82      0.82        50\n",
      "\n",
      "    accuracy                           0.77        77\n",
      "   macro avg       0.74      0.74      0.74        77\n",
      "weighted avg       0.77      0.77      0.77        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 76.62  %\n",
      "Presisi fold ini adalah : 66.67  %\n",
      "Recall fold ini adalah : 66.67  %\n",
      "===========================================================\n",
      "Fold yang ke 7 dengan data bootstrap berjumlah : 10\n",
      "Menghasilkan tree berjumlah : 10\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "419      Normal  Rendah        Normal        Tinggi  Rendah  Tinggi   \n",
      "424      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "425      Normal  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "427      Rendah  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "429      Rendah  Rendah        Tinggi        Normal  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction  Age  Outcome  \n",
      "419                   Rendah  Tua      1.0  \n",
      "424                   Normal  Tua      1.0  \n",
      "425                   Rendah  Tua      1.0  \n",
      "427                   Rendah  Tua      1.0  \n",
      "429                   Rendah  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "    Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9  Pred10\n",
      "0     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "1     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "2     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "3     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "4     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
      "72    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "73    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "74    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "75    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "76    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "\n",
      "[77 rows x 10 columns]\n",
      "y_pred :\n",
      "      P7\n",
      "0   0.0\n",
      "1   0.0\n",
      "2   1.0\n",
      "3   0.0\n",
      "4   1.0\n",
      "..  ...\n",
      "72  0.0\n",
      "73  0.0\n",
      "74  1.0\n",
      "75  0.0\n",
      "76  0.0\n",
      "\n",
      "[77 rows x 1 columns]\n",
      "Confusion matrix : \n",
      " [[13 14]\n",
      " [ 9 41]]\n",
      "\n",
      "True positive : 13\n",
      "False negative : 14\n",
      "False positive : 9\n",
      "True negative : 41\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.48      0.53        27\n",
      "           0       0.75      0.82      0.78        50\n",
      "\n",
      "    accuracy                           0.70        77\n",
      "   macro avg       0.67      0.65      0.66        77\n",
      "weighted avg       0.69      0.70      0.69        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 70.13  %\n",
      "Presisi fold ini adalah : 59.09  %\n",
      "Recall fold ini adalah : 48.15  %\n",
      "===========================================================\n",
      "Fold yang ke 8 dengan data bootstrap berjumlah : 10\n",
      "Menghasilkan tree berjumlah : 10\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "535      Normal  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "539      Normal  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "540      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "541      Normal  Rendah        Normal        Normal  Tinggi  Tinggi   \n",
      "542      Tinggi  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction     Age  Outcome  \n",
      "535                   Rendah  Dewasa      1.0  \n",
      "539                   Normal     Tua      1.0  \n",
      "540                   Normal     Tua      1.0  \n",
      "541                   Normal     Tua      1.0  \n",
      "542                   Normal     Tua      1.0  \n",
      "Panjang data test : 76\n",
      "Panjang data train : 692\n",
      "    Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9  Pred10\n",
      "0     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "1     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "2     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "3     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "4     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
      "71    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "72    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "73    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "74    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "75    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "\n",
      "[76 rows x 10 columns]\n",
      "y_pred :\n",
      "      P8\n",
      "0   0.0\n",
      "1   0.0\n",
      "2   1.0\n",
      "3   1.0\n",
      "4   1.0\n",
      "..  ...\n",
      "71  1.0\n",
      "72  0.0\n",
      "73  1.0\n",
      "74  0.0\n",
      "75  0.0\n",
      "\n",
      "[76 rows x 1 columns]\n",
      "Confusion matrix : \n",
      " [[21  5]\n",
      " [13 37]]\n",
      "\n",
      "True positive : 21\n",
      "False negative : 5\n",
      "False positive : 13\n",
      "True negative : 37\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.81      0.70        26\n",
      "           0       0.88      0.74      0.80        50\n",
      "\n",
      "    accuracy                           0.76        76\n",
      "   macro avg       0.75      0.77      0.75        76\n",
      "weighted avg       0.79      0.76      0.77        76\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 76.32  %\n",
      "Presisi fold ini adalah : 61.76  %\n",
      "Recall fold ini adalah : 80.77  %\n",
      "===========================================================\n",
      "Fold yang ke 9 dengan data bootstrap berjumlah : 10\n",
      "Menghasilkan tree berjumlah : 10\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "618      Tinggi  Rendah        Tinggi        Normal  Tinggi  Tinggi   \n",
      "619      Rendah  Rendah        Normal        Normal  Tinggi  Tinggi   \n",
      "630      Tinggi  Rendah        Normal        Tinggi  Normal  Tinggi   \n",
      "635      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "638      Tinggi  Rendah        Normal        Tinggi  Rendah  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction  Age  Outcome  \n",
      "618                   Tinggi  Tua      1.0  \n",
      "619                   Rendah  Tua      1.0  \n",
      "630                   Normal  Tua      1.0  \n",
      "635                   Rendah  Tua      1.0  \n",
      "638                   Normal  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "    Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9  Pred10\n",
      "0     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "1     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "2     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "3     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "4     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
      "72    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "73    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "74    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "75    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "76    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "\n",
      "[77 rows x 10 columns]\n",
      "y_pred :\n",
      "      P9\n",
      "0   0.0\n",
      "1   1.0\n",
      "2   0.0\n",
      "3   1.0\n",
      "4   1.0\n",
      "..  ...\n",
      "72  1.0\n",
      "73  0.0\n",
      "74  0.0\n",
      "75  0.0\n",
      "76  1.0\n",
      "\n",
      "[77 rows x 1 columns]\n",
      "Confusion matrix : \n",
      " [[18  9]\n",
      " [16 34]]\n",
      "\n",
      "True positive : 18\n",
      "False negative : 9\n",
      "False positive : 16\n",
      "True negative : 34\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.67      0.59        27\n",
      "           0       0.79      0.68      0.73        50\n",
      "\n",
      "    accuracy                           0.68        77\n",
      "   macro avg       0.66      0.67      0.66        77\n",
      "weighted avg       0.70      0.68      0.68        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 67.53  %\n",
      "Presisi fold ini adalah : 52.94  %\n",
      "Recall fold ini adalah : 66.67  %\n",
      "===========================================================\n",
      "Fold yang ke 10 dengan data bootstrap berjumlah : 10\n",
      "Menghasilkan tree berjumlah : 10\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "701      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "702      Rendah  Normal        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "706      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "708      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "709      Normal  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction     Age  Outcome  \n",
      "701                   Normal     Tua      1.0  \n",
      "702                   Normal     Tua      1.0  \n",
      "706                   Rendah     Tua      1.0  \n",
      "708                   Rendah     Tua      1.0  \n",
      "709                   Normal  Dewasa      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "    Pred1  Pred2  Pred3  Pred4  Pred5  Pred6  Pred7  Pred8  Pred9  Pred10\n",
      "0     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "1     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "2     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "3     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "4     1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
      "72    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "73    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
      "74    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "75    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "76    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0\n",
      "\n",
      "[77 rows x 10 columns]\n",
      "y_pred :\n",
      "     P10\n",
      "0   1.0\n",
      "1   1.0\n",
      "2   1.0\n",
      "3   1.0\n",
      "4   1.0\n",
      "..  ...\n",
      "72  0.0\n",
      "73  1.0\n",
      "74  0.0\n",
      "75  0.0\n",
      "76  0.0\n",
      "\n",
      "[77 rows x 1 columns]\n",
      "Confusion matrix : \n",
      " [[22  5]\n",
      " [ 7 43]]\n",
      "\n",
      "True positive : 22\n",
      "False negative : 5\n",
      "False positive : 7\n",
      "True negative : 43\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.81      0.79        27\n",
      "           0       0.90      0.86      0.88        50\n",
      "\n",
      "    accuracy                           0.84        77\n",
      "   macro avg       0.83      0.84      0.83        77\n",
      "weighted avg       0.85      0.84      0.85        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 84.42  %\n",
      "Presisi fold ini adalah : 75.86  %\n",
      "Recall fold ini adalah : 81.48  %\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "prediksi_final_id3bagging, akurasi_id3bagging, presisi_id3bagging, recall_id3bagging = id3bagging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold yang ke 1 dengan data training berjumlah : 691\n",
      "Data yang akan diuji sebagai berikut :\n",
      "   Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "0      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "2      Tinggi  Normal        Normal        Tinggi  Tinggi  Normal   \n",
      "4      Rendah  Rendah        Rendah        Tinggi  Tinggi  Tinggi   \n",
      "6      Normal  Rendah        Rendah        Tinggi  Rendah  Tinggi   \n",
      "8      Normal  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "  DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                   Normal  Tua      1.0  \n",
      "2                   Normal  Tua      1.0  \n",
      "4                   Tinggi  Tua      1.0  \n",
      "6                   Rendah  Tua      1.0  \n",
      "8                   Rendah  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "y_pred :\n",
      " [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Confusion matrix : \n",
      " [[18  9]\n",
      " [17 33]]\n",
      "\n",
      "True positive : 18\n",
      "False negative : 9\n",
      "False positive : 17\n",
      "True negative : 33\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.67      0.58        27\n",
      "           0       0.79      0.66      0.72        50\n",
      "\n",
      "    accuracy                           0.66        77\n",
      "   macro avg       0.65      0.66      0.65        77\n",
      "weighted avg       0.69      0.66      0.67        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 66.23  %\n",
      "Presisi fold ini adalah : 51.43  %\n",
      "Recall fold ini adalah : 66.67  %\n",
      "===========================================================\n",
      "Fold yang ke 2 dengan data training berjumlah : 691\n",
      "Data yang akan diuji sebagai berikut :\n",
      "    Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "61      Tinggi  Rendah        Normal        Tinggi  Normal  Tinggi   \n",
      "64      Tinggi  Rendah        Normal        Normal  Tinggi  Tinggi   \n",
      "66      Rendah  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "70      Normal  Rendah        Normal        Normal  Rendah  Tinggi   \n",
      "72      Tinggi  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "61                   Rendah  Tua      1.0  \n",
      "64                   Rendah  Tua      1.0  \n",
      "66                   Normal  Tua      1.0  \n",
      "70                   Normal  Tua      1.0  \n",
      "72                   Normal  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "y_pred :\n",
      " [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Confusion matrix : \n",
      " [[14 13]\n",
      " [10 40]]\n",
      "\n",
      "True positive : 14\n",
      "False negative : 13\n",
      "False positive : 10\n",
      "True negative : 40\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.52      0.55        27\n",
      "           0       0.75      0.80      0.78        50\n",
      "\n",
      "    accuracy                           0.70        77\n",
      "   macro avg       0.67      0.66      0.66        77\n",
      "weighted avg       0.69      0.70      0.70        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 70.13  %\n",
      "Presisi fold ini adalah : 58.33  %\n",
      "Recall fold ini adalah : 51.85  %\n",
      "===========================================================\n",
      "Fold yang ke 3 dengan data training berjumlah : 692\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "154      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "155      Tinggi  Normal        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "159      Tinggi  Normal        Normal        Tinggi  Rendah  Tinggi   \n",
      "164      Rendah  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "165      Tinggi  Rendah        Normal        Normal  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction  Age  Outcome  \n",
      "154                   Rendah  Tua      1.0  \n",
      "155                   Rendah  Tua      1.0  \n",
      "159                   Normal  Tua      1.0  \n",
      "164                   Normal  Tua      1.0  \n",
      "165                   Normal  Tua      1.0  \n",
      "Panjang data test : 76\n",
      "Panjang data train : 692\n",
      "y_pred :\n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "Confusion matrix : \n",
      " [[21  5]\n",
      " [ 8 42]]\n",
      "\n",
      "True positive : 21\n",
      "False negative : 5\n",
      "False positive : 8\n",
      "True negative : 42\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.81      0.76        26\n",
      "           0       0.89      0.84      0.87        50\n",
      "\n",
      "    accuracy                           0.83        76\n",
      "   macro avg       0.81      0.82      0.81        76\n",
      "weighted avg       0.84      0.83      0.83        76\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 82.89  %\n",
      "Presisi fold ini adalah : 72.41  %\n",
      "Recall fold ini adalah : 80.77  %\n",
      "===========================================================\n",
      "Fold yang ke 4 dengan data training berjumlah : 691\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "215      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "216      Tinggi  Rendah        Normal        Tinggi  Normal  Tinggi   \n",
      "218      Tinggi  Rendah        Normal        Normal  Normal  Tinggi   \n",
      "219      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "220      Rendah  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction     Age  Outcome  \n",
      "215                   Normal     Tua      1.0  \n",
      "216                   Normal     Tua      1.0  \n",
      "218                   Tinggi     Tua      1.0  \n",
      "219                   Rendah     Tua      1.0  \n",
      "220                   Tinggi  Dewasa      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "y_pred :\n",
      " [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 1.0, 1.0, 1.0]\n",
      "Confusion matrix : \n",
      " [[21  6]\n",
      " [14 36]]\n",
      "\n",
      "True positive : 21\n",
      "False negative : 6\n",
      "False positive : 14\n",
      "True negative : 36\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.78      0.68        27\n",
      "           0       0.86      0.72      0.78        50\n",
      "\n",
      "    accuracy                           0.74        77\n",
      "   macro avg       0.73      0.75      0.73        77\n",
      "weighted avg       0.77      0.74      0.75        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 74.03  %\n",
      "Presisi fold ini adalah : 60.0  %\n",
      "Recall fold ini adalah : 77.78  %\n",
      "===========================================================\n",
      "Fold yang ke 5 dengan data training berjumlah : 691\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "284      Normal  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "287      Rendah  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "291      Rendah  Rendah        Normal        Tinggi  Rendah  Tinggi   \n",
      "292      Normal  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "293      Rendah  Rendah        Rendah        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction  Age  Outcome  \n",
      "284                   Rendah  Tua      1.0  \n",
      "287                   Normal  Tua      1.0  \n",
      "291                   Normal  Tua      1.0  \n",
      "292                   Tinggi  Tua      1.0  \n",
      "293                   Normal  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "y_pred :\n",
      " [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0, 0.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0, 0.0, 1.0, 0.0]\n",
      "Confusion matrix : \n",
      " [[18  9]\n",
      " [ 9 41]]\n",
      "\n",
      "True positive : 18\n",
      "False negative : 9\n",
      "False positive : 9\n",
      "True negative : 41\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.67      0.67        27\n",
      "           0       0.82      0.82      0.82        50\n",
      "\n",
      "    accuracy                           0.77        77\n",
      "   macro avg       0.74      0.74      0.74        77\n",
      "weighted avg       0.77      0.77      0.77        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 76.62  %\n",
      "Presisi fold ini adalah : 66.67  %\n",
      "Recall fold ini adalah : 66.67  %\n",
      "===========================================================\n",
      "Fold yang ke 6 dengan data training berjumlah : 691\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "355      Tinggi  Normal        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "356      Rendah  Rendah        Rendah        Tinggi  Tinggi  Tinggi   \n",
      "357      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "359      Rendah  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "360      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction  Age  Outcome  \n",
      "355                   Rendah  Tua      1.0  \n",
      "356                   Normal  Tua      1.0  \n",
      "357                   Normal  Tua      1.0  \n",
      "359                   Normal  Tua      1.0  \n",
      "360                   Normal  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "y_pred :\n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Confusion matrix : \n",
      " [[17 10]\n",
      " [12 38]]\n",
      "\n",
      "True positive : 17\n",
      "False negative : 10\n",
      "False positive : 12\n",
      "True negative : 38\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.63      0.61        27\n",
      "           0       0.79      0.76      0.78        50\n",
      "\n",
      "    accuracy                           0.71        77\n",
      "   macro avg       0.69      0.69      0.69        77\n",
      "weighted avg       0.72      0.71      0.72        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 71.43  %\n",
      "Presisi fold ini adalah : 58.62  %\n",
      "Recall fold ini adalah : 62.96  %\n",
      "===========================================================\n",
      "Fold yang ke 7 dengan data training berjumlah : 691\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "419      Normal  Rendah        Normal        Tinggi  Rendah  Tinggi   \n",
      "424      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "425      Normal  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "427      Rendah  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "429      Rendah  Rendah        Tinggi        Normal  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction  Age  Outcome  \n",
      "419                   Rendah  Tua      1.0  \n",
      "424                   Normal  Tua      1.0  \n",
      "425                   Rendah  Tua      1.0  \n",
      "427                   Rendah  Tua      1.0  \n",
      "429                   Rendah  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "y_pred :\n",
      " [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0, 1.0, 0.0, 0]\n",
      "Confusion matrix : \n",
      " [[19  8]\n",
      " [ 9 41]]\n",
      "\n",
      "True positive : 19\n",
      "False negative : 8\n",
      "False positive : 9\n",
      "True negative : 41\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.70      0.69        27\n",
      "           0       0.84      0.82      0.83        50\n",
      "\n",
      "    accuracy                           0.78        77\n",
      "   macro avg       0.76      0.76      0.76        77\n",
      "weighted avg       0.78      0.78      0.78        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 77.92  %\n",
      "Presisi fold ini adalah : 67.86  %\n",
      "Recall fold ini adalah : 70.37  %\n",
      "===========================================================\n",
      "Fold yang ke 8 dengan data training berjumlah : 692\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "535      Normal  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "539      Normal  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "540      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "541      Normal  Rendah        Normal        Normal  Tinggi  Tinggi   \n",
      "542      Tinggi  Rendah        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction     Age  Outcome  \n",
      "535                   Rendah  Dewasa      1.0  \n",
      "539                   Normal     Tua      1.0  \n",
      "540                   Normal     Tua      1.0  \n",
      "541                   Normal     Tua      1.0  \n",
      "542                   Normal     Tua      1.0  \n",
      "Panjang data test : 76\n",
      "Panjang data train : 692\n",
      "y_pred :\n",
      " [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "Confusion matrix : \n",
      " [[20  6]\n",
      " [ 9 41]]\n",
      "\n",
      "True positive : 20\n",
      "False negative : 6\n",
      "False positive : 9\n",
      "True negative : 41\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.77      0.73        26\n",
      "           0       0.87      0.82      0.85        50\n",
      "\n",
      "    accuracy                           0.80        76\n",
      "   macro avg       0.78      0.79      0.79        76\n",
      "weighted avg       0.81      0.80      0.80        76\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 80.26  %\n",
      "Presisi fold ini adalah : 68.97  %\n",
      "Recall fold ini adalah : 76.92  %\n",
      "===========================================================\n",
      "Fold yang ke 9 dengan data training berjumlah : 691\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "618      Tinggi  Rendah        Tinggi        Normal  Tinggi  Tinggi   \n",
      "619      Rendah  Rendah        Normal        Normal  Tinggi  Tinggi   \n",
      "630      Tinggi  Rendah        Normal        Tinggi  Normal  Tinggi   \n",
      "635      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "638      Tinggi  Rendah        Normal        Tinggi  Rendah  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction  Age  Outcome  \n",
      "618                   Tinggi  Tua      1.0  \n",
      "619                   Rendah  Tua      1.0  \n",
      "630                   Normal  Tua      1.0  \n",
      "635                   Rendah  Tua      1.0  \n",
      "638                   Normal  Tua      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "y_pred :\n",
      " [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0, 0.0, 1.0, 1.0, 0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "Confusion matrix : \n",
      " [[18  9]\n",
      " [10 40]]\n",
      "\n",
      "True positive : 18\n",
      "False negative : 9\n",
      "False positive : 10\n",
      "True negative : 40\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.67      0.65        27\n",
      "           0       0.82      0.80      0.81        50\n",
      "\n",
      "    accuracy                           0.75        77\n",
      "   macro avg       0.73      0.73      0.73        77\n",
      "weighted avg       0.76      0.75      0.75        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 75.32  %\n",
      "Presisi fold ini adalah : 64.29  %\n",
      "Recall fold ini adalah : 66.67  %\n",
      "===========================================================\n",
      "Fold yang ke 10 dengan data training berjumlah : 691\n",
      "Data yang akan diuji sebagai berikut :\n",
      "     Pregnancies Glucose BloodPressure SkinThickness Insulin     BMI  \\\n",
      "701      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "702      Rendah  Normal        Tinggi        Tinggi  Tinggi  Tinggi   \n",
      "706      Tinggi  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "708      Tinggi  Normal        Normal        Tinggi  Tinggi  Tinggi   \n",
      "709      Normal  Rendah        Normal        Tinggi  Tinggi  Tinggi   \n",
      "\n",
      "    DiabetesPedigreeFunction     Age  Outcome  \n",
      "701                   Normal     Tua      1.0  \n",
      "702                   Normal     Tua      1.0  \n",
      "706                   Rendah     Tua      1.0  \n",
      "708                   Rendah     Tua      1.0  \n",
      "709                   Normal  Dewasa      1.0  \n",
      "Panjang data test : 77\n",
      "Panjang data train : 691\n",
      "y_pred :\n",
      " [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0, 0.0, 0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "Confusion matrix : \n",
      " [[16 11]\n",
      " [ 9 41]]\n",
      "\n",
      "True positive : 16\n",
      "False negative : 11\n",
      "False positive : 9\n",
      "True negative : 41\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.59      0.62        27\n",
      "           0       0.79      0.82      0.80        50\n",
      "\n",
      "    accuracy                           0.74        77\n",
      "   macro avg       0.71      0.71      0.71        77\n",
      "weighted avg       0.74      0.74      0.74        77\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 74.03  %\n",
      "Presisi fold ini adalah : 64.0  %\n",
      "Recall fold ini adalah : 59.26  %\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "prediksi_final_id3, akurasi_id3, presisi_id3, recall_id3 = id3biasa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perbandingan Akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_c45 = pd.read_excel('output_c45.xlsx')\n",
    "akurasi_c45 = dat_c45[\"C45\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabelAkurasi():\n",
    "    dat = []\n",
    "\n",
    "    for i in range(len(akurasi_id3)):\n",
    "        dat.append([str(i+1),akurasi_id3[i],akurasi_id3bagging[i], akurasi_c45[i]])\n",
    "\n",
    "    dat2 = pd.DataFrame(dat, columns=['Fold', 'ID3', 'ID3 Bagging', 'C45'])\n",
    "    print(\"Akurasi tertinggi ID3 tanpa Bagging :\",max(akurasi_id3))\n",
    "    print(\"Akurasi tertinggi ID3 dengan Bagging :\",max(akurasi_id3bagging))\n",
    "    print(\"Akurasi tertinggi C45 :\",max(akurasi_c45))\n",
    "\n",
    "    return dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi tertinggi ID3 tanpa Bagging : 82.89\n",
      "Akurasi tertinggi ID3 dengan Bagging : 84.42\n",
      "Akurasi tertinggi C45 : 88.31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>ID3</th>\n",
       "      <th>ID3 Bagging</th>\n",
       "      <th>C45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>66.23</td>\n",
       "      <td>71.43</td>\n",
       "      <td>76.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>70.13</td>\n",
       "      <td>74.03</td>\n",
       "      <td>76.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>82.89</td>\n",
       "      <td>80.26</td>\n",
       "      <td>81.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>74.03</td>\n",
       "      <td>68.83</td>\n",
       "      <td>80.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>76.62</td>\n",
       "      <td>74.03</td>\n",
       "      <td>83.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>71.43</td>\n",
       "      <td>76.62</td>\n",
       "      <td>81.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>77.92</td>\n",
       "      <td>70.13</td>\n",
       "      <td>77.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>80.26</td>\n",
       "      <td>76.32</td>\n",
       "      <td>85.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>75.32</td>\n",
       "      <td>67.53</td>\n",
       "      <td>76.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>74.03</td>\n",
       "      <td>84.42</td>\n",
       "      <td>88.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Fold    ID3  ID3 Bagging    C45\n",
       "0    1  66.23        71.43  76.62\n",
       "1    2  70.13        74.03  76.62\n",
       "2    3  82.89        80.26  81.58\n",
       "3    4  74.03        68.83  80.52\n",
       "4    5  76.62        74.03  83.12\n",
       "5    6  71.43        76.62  81.82\n",
       "6    7  77.92        70.13  77.92\n",
       "7    8  80.26        76.32  85.53\n",
       "8    9  75.32        67.53  76.62\n",
       "9   10  74.03        84.42  88.31"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Akurasi = tabelAkurasi()\n",
    "Akurasi.to_excel(\"output_perbandingan_akurasi.xlsx\", index=False)  \n",
    "Akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = [str(i+1) for i in range(10)]\n",
    "\n",
    "def perAkurasi() :\n",
    "    # plotting the line 1 points\n",
    "    plt.plot(k, akurasi_id3, label = \"ID3\", marker='o', markerfacecolor='blue', markersize=5)\n",
    "    # plotting the line 2 points\n",
    "    plt.plot(k, akurasi_id3bagging, label = \"ID3 Bagging\", marker='o', markerfacecolor='red', markersize=5)\n",
    "    # plotting the line 3 points\n",
    "    plt.plot(k, akurasi_c45, label = \"C45\", marker='o', markerfacecolor='green', markersize=5)\n",
    "\n",
    "    # naming the x axis\n",
    "    plt.xlabel('Fold')\n",
    "    # naming the y axis\n",
    "    plt.ylabel('Akurasi')\n",
    "    # giving a title to my graph\n",
    "    plt.title('Perbandingan akurasi')\n",
    "\n",
    "    # show a legend on the plot\n",
    "    plt.legend()\n",
    "\n",
    "    # function to show the plot\n",
    "    plt.show()\n",
    "\n",
    "def perPresisi():\n",
    "    # plotting the line 1 points\n",
    "    plt.plot(k, presisi_id3, label = \"ID3\", marker='o', markerfacecolor='blue', markersize=5)\n",
    "    # plotting the line 2 points\n",
    "    plt.plot(k, presisi_id3bagging, label = \"ID3 Bagging\", marker='o', markerfacecolor='red', markersize=5)\n",
    "    \n",
    "    # naming the x axis\n",
    "    plt.xlabel('Fold')\n",
    "    # naming the y axis\n",
    "    plt.ylabel('Presisi')\n",
    "    # giving a title to my graph\n",
    "    plt.title('Perbandingan presisi')\n",
    "    \n",
    "    # show a legend on the plot\n",
    "    plt.legend()\n",
    "    \n",
    "    # function to show the plot\n",
    "    plt.show()\n",
    "\n",
    "def perRecall():\n",
    "    # plotting the line 1 points\n",
    "    plt.plot(k, recall_id3, label = \"ID3\", marker='o', markerfacecolor='blue', markersize=5)\n",
    "    # plotting the line 2 points\n",
    "    plt.plot(k, recall_id3bagging, label = \"ID3 Bagging\", marker='o', markerfacecolor='red', markersize=5)\n",
    "    \n",
    "    # naming the x axis\n",
    "    plt.xlabel('Fold')\n",
    "    # naming the y axis\n",
    "    plt.ylabel('Recall')\n",
    "    # giving a title to my graph\n",
    "    plt.title('Perbandingan recall')\n",
    "    \n",
    "    # show a legend on the plot\n",
    "    plt.legend()\n",
    "    \n",
    "    # function to show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perAkurasi()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
